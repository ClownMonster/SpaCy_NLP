{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Working with linguistic features\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Deep learning is an artificial intelligence function that imitates the workings of the human brain in processing data and creating patterns for use in decision making . .. Also known as deep neural learning or deep neural network"
    }
   ],
   "source": [
    "# Parts of speech tagging\n",
    "# To get en_core_web_sm need to get the package by \"python3 -m spacy download en\"\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "'''\n",
    "u can also load as --> nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "'''\n",
    "\n",
    "paragraph = \"Deep learning is an artificial intelligence function that imitates the workings of the human brain in processing data and creating patterns for use in decision making. .. Also known as deep neural learning or deep neural network\"\n",
    "\n",
    "doc = nlp(paragraph)\n",
    "\n",
    "# get the token is the nlp document\n",
    "for token in doc:\n",
    "    print(token, end = ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Deep deep JJ ADJ Xxxx True False\nlearning learning NN NOUN xxxx True False\nis be VBZ AUX xx True True\nan an DT DET xx True True\nartificial artificial JJ ADJ xxxx True False\nintelligence intelligence NN NOUN xxxx True False\nfunction function NN NOUN xxxx True False\nthat that WDT DET xxxx True True\nimitates imitate VBZ VERB xxxx True False\nthe the DT DET xxx True True\nworkings working NNS NOUN xxxx True False\nof of IN ADP xx True True\nthe the DT DET xxx True True\nhuman human JJ ADJ xxxx True False\nbrain brain NN NOUN xxxx True False\nin in IN ADP xx True True\nprocessing process VBG VERB xxxx True False\ndata datum NNS NOUN xxxx True False\nand and CC CCONJ xxx True True\ncreating create VBG VERB xxxx True False\npatterns pattern NNS NOUN xxxx True False\nfor for IN ADP xxx True True\nuse use NN NOUN xxx True False\nin in IN ADP xx True True\ndecision decision NN NOUN xxxx True False\nmaking making NN NOUN xxxx True False\n. . . PUNCT . False False\n.. .. NFP PUNCT .. False False\nAlso also RB ADV Xxxx True True\nknown know VBN VERB xxxx True False\nas as IN SCONJ xx True True\ndeep deep JJ ADJ xxxx True False\nneural neural JJ ADJ xxxx True False\nlearning learning NN NOUN xxxx True False\nor or CC CCONJ xx True True\ndeep deep JJ ADJ xxxx True False\nneural neural JJ ADJ xxxx True False\nnetwork network NN NOUN xxxx True False\n"
    }
   ],
   "source": [
    "# each token string representation\n",
    "# properties of each token\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,  token.lemma_, token.tag_, token.pos_, token.shape_, token.is_alpha, token.is_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Deep learning learning nsubj is\nan artificial intelligence function function attr is\nthe workings workings dobj imitates\nthe human brain brain pobj of\ndata data dobj processing\npatterns patterns dobj creating\nuse use pobj for\ndecision making making pobj in\ndeep neural learning learning pobj as\ndeep neural network network conj learning\n"
    }
   ],
   "source": [
    "'''\n",
    "Dependency parsing\n",
    "\n",
    "'''\n",
    "\n",
    "# Noun Chunks\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{imitates}\n"
    }
   ],
   "source": [
    "# finding verb with subject\n",
    "\n",
    "verbs = set()\n",
    "\n",
    "for subjects in doc:\n",
    "    if subjects.dep_ == 'nsubj' and subjects.head.pos_ == 'VERB':\n",
    "        verbs.add(subjects.head)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['learning']\n['function', '.', '..']\n1\n3\n"
    }
   ],
   "source": [
    "# find the left and rights of a doc token\n",
    "\n",
    "print([token.text for token in doc[2].lefts])\n",
    "print([token.text for token in doc[2].rights])\n",
    "\n",
    "print(doc[2].n_lefts) # items to the left\n",
    "print(doc[2].n_rights) # items to the right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit0101c40685f74ac2afe19d6555c1a2e3",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}